{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ml package Inports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "# import torch.optim.lr_scheduler as lr_scheduler\n",
    "# from torch.autograd import Variable\n",
    "# from torch.nn.functional import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper package Imports\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from pytorch_msssim import SSIM, MS_SSIM, ssim, ms_ssim\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from kornia.color import rgb_to_lab, bgr_to_rgb, lab_to_rgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d mariomatos/image-colorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Dimension and Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = 256\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "data_path = \"./Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Dataset and renameing folder\n",
    "if not Path(data_path).is_dir():\n",
    "    # Extract Data From Zip File\n",
    "    with ZipFile('image-colorization.zip',\"r\") as z:\n",
    "        z.extractall(path = data_path)\n",
    "    old_path = data_path + str(os.listdir(data_path)[0])\n",
    "    \n",
    "    image_paths = [f'{old_path}/{img}' for img in os.listdir(old_path)]\n",
    "    \n",
    "    # Change Data Directory to ./Data/...\n",
    "    print(\"Changing Image Directory >>\")\n",
    "    for i in trange(len(image_paths)):\n",
    "        shutil.move(image_paths[i], data_path)\n",
    "    \n",
    "    os.rmdir(old_path)\n",
    "    image_paths = [f'{data_path}{img}' for img in os.listdir(data_path)]\n",
    "    print(f\"Total Images Ectracted from the Dataset\\t\\t: {len(image_paths)}\")\n",
    "    \n",
    "    # Remove Grayscale Images\n",
    "    print(\"Removing Grayscale Images >>\")\n",
    "    for i in trange(len(image_paths)):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = torch.from_numpy(img).permute(2,0,1)        \n",
    "        \n",
    "        if torch.mean(((img[0] == img[1]) == (img[1] == img[2])).float()) == 1:\n",
    "            os.remove(image_paths[i])\n",
    "    \n",
    "    print(f\"Total Images after Removing Grayscale Images\\t: {len(os.listdir(data_path))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename check\n",
    "imgs = os.listdir(data_path)\n",
    "print(f'Total Images : {len(imgs)}')\n",
    "print(f'Sample Image Name : {imgs[random.randint(0, len(imgs))]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_Norm(ab_x):\n",
    "    ab = torch.clone(ab_x)\n",
    "    ab = ab * 128\n",
    "    return ab.long()\n",
    "\n",
    "def ab_UnNorm(ab_x):\n",
    "    ab = torch.clone(ab_x)\n",
    "    ab = ab / 128\n",
    "    return ab.float()\n",
    "\n",
    "def l_Norm(l_x):\n",
    "    l = torch.clone(l_x)\n",
    "    l = (l * 100) + 50\n",
    "    return l.long()\n",
    "\n",
    "def l_UnNorm(l_x):\n",
    "    l = torch.clone(l_x)\n",
    "    l = (l - 50) / 100\n",
    "    return l.float()\n",
    "\n",
    "def fullImg(inp, tar):\n",
    "    return torch.cat((inp, tar), 0)\n",
    "\n",
    "def getRGB(img):\n",
    "    x = torch.clone(img)\n",
    "    x[0] = (x[0] * 100) + 50\n",
    "    x[1:] = x[1:] * 128\n",
    "    return (lab_to_rgb(x) * 255).long() \n",
    "\n",
    "def getRGBs(img):\n",
    "    x = torch.clone(img)\n",
    "    x[0:, 0, 0:, 0:] = (x[0:, 0, 0:, 0:] * 100) + 50\n",
    "    x[0:, 1:, 0:, 0:] = x[0:, 1:, 0:, 0:] * 128\n",
    "    return (lab_to_rgb(x) * 255).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "class DatasetBNW(Dataset):\n",
    "    def __init__(self, path=data_path, transform=None):\n",
    "        self.data = [f'{path}{img}' for img in os.listdir(path)]\n",
    "        self.length = len(self.data)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.data[index])\n",
    "        img = cv2.resize(img, (img_dim, img_dim))\n",
    "        \n",
    "        img = torch.from_numpy(img).permute(2,0,1)\n",
    "        \n",
    "        img = bgr_to_rgb(img) / 255\n",
    "        img = rgb_to_lab(img)\n",
    "    \n",
    "        input_img = img[0,0:,0:].view(1,img_dim,img_dim)\n",
    "        input_img = l_UnNorm(input_img)\n",
    "        \n",
    "        target_img = img[1:,0:,0:]\n",
    "        target_img = ab_UnNorm(target_img)\n",
    "        \n",
    "        return input_img, target_img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet\n",
    "dataset = DatasetBNW()\n",
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Dataset Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = dataset[random.randint(0, len(dataset))]\n",
    "f = fullImg(inp, tar)\n",
    "full = getRGB(f)\n",
    "\n",
    "plt.figure(figsize=(50,50), dpi=50)\n",
    "\n",
    "plt.subplot(241)\n",
    "plt.title('Input', fontdict = {'fontsize': 30})\n",
    "plt.imshow(inp.permute(1,2,0), cmap = 'gray')\n",
    "\n",
    "plt.subplot(242)\n",
    "plt.title('Target', fontdict = {'fontsize': 30})\n",
    "plt.imshow(full.permute(1,2,0), cmap = 'gray')\n",
    "\n",
    "plt.subplot(243)\n",
    "plt.title('Channel A', fontdict = {'fontsize': 30})\n",
    "plt.imshow(tar[0,0:,0:].view(1,img_dim,img_dim).permute(1,2,0), cmap = 'gray')\n",
    "\n",
    "plt.subplot(244)\n",
    "plt.title('Channel B', fontdict = {'fontsize': 30})\n",
    "plt.imshow(tar[1,0:,0:].view(1,img_dim,img_dim).permute(1,2,0), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test data\n",
    "def split_indices(n, val_pct, test_pct, seed=65):\n",
    "    # determine the size of the validation set, test set\n",
    "    n_val = int(val_pct*n)\n",
    "    n_test = int(test_pct*n + n_val)\n",
    "    # print(n_val, n_test, n_train)\n",
    "    # create random parmutation of 0 to n-1\n",
    "    np.random.seed(seed)\n",
    "    idxs = np.random.permutation(n)\n",
    "    # pick data as train[start-val], validation[val-test] and test[test-end]\n",
    "    return idxs[n_test:], idxs[:n_val], idxs[n_val:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training, validation and test set\n",
    "train_indices, val_indices, test_indices = split_indices(len(dataset), 0.2, 0.1)\n",
    "print(f\"\"\"\n",
    "        Training Images   : {len(train_indices)}\\n\n",
    "        Validation Images : {len(val_indices)}\\n\n",
    "        Testing Images    : {len(test_indices)}\\n\n",
    "        Total Images      : {len(train_indices) + len(val_indices) + len(test_indices)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sampler and dataloader\n",
    "train_sampler = SubsetRandomSampler(train_indices)    # takes samples w.r.t the indices\n",
    "train_dl = DataLoader(dataset,\n",
    "                      batch_size,\n",
    "                      sampler = train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation sampler and dataloader\n",
    "val_sampler = SubsetRandomSampler(val_indices)        # takes samples w.r.t the indices\n",
    "val_dl = DataLoader(dataset,\n",
    "                    batch_size,\n",
    "                    sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sampler and dataloader\n",
    "test_sampler = SubsetRandomSampler(test_indices)        # takes samples w.r.t the indices\n",
    "test_dl = DataLoader(dataset,\n",
    "                     batch_size,\n",
    "                     sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Accuracy Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracies = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show and Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltSubpot(cord, pos, cp, title, pic, titleShow = True):\n",
    "    plt.subplot2grid(cord, pos, colspan=cp)\n",
    "    plt.axis('off')\n",
    "    if titleShow:\n",
    "        plt.title(title, fontdict = {'fontsize': 20})    \n",
    "    plt.imshow(pic, cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testResult(t_model, idx = None, savePath = None, name = None, show = True):\n",
    "    if idx == None:\n",
    "        inp, tgt = dataset[(random.choices(list(test_sampler.indices))[0])]\n",
    "    else:\n",
    "        inp, tgt = dataset[list(test_sampler.indices)[idx]]\n",
    "    \n",
    "    out = t_model(inp.unsqueeze(0).cpu())\n",
    "    out = out.squeeze(0).cpu()\n",
    "    \n",
    "    target = fullImg(inp, tgt)\n",
    "    \n",
    "    if not Path(f'{savePath}').is_dir():\n",
    "        Path.mkdir(Path(f'{savePath}'))\n",
    "        \n",
    "    fig = plt.figure(figsize=(25,25), dpi=45)\n",
    "    \n",
    "    graph_dim = (3, 6)\n",
    "    \n",
    "    # input\n",
    "    pltSubpot(graph_dim, (0, 0), 2, 'Input', inp.permute(1,2,0))\n",
    "    \n",
    "    # target\n",
    "    pltSubpot(graph_dim, (0, 2), 2, 'Target', getRGB(target).permute(1,2,0))\n",
    "    \n",
    "    # output\n",
    "    pltSubpot(graph_dim, (0, 4), 2, 'Output', getRGB(out).permute(1,2,0))\n",
    "    \n",
    "    if name != None:\n",
    "        # target L\n",
    "        pltSubpot(graph_dim, (1, 0), 2, 'target L Channel', target[0,0:,0:].cpu())\n",
    "\n",
    "        # target A\n",
    "        pltSubpot(graph_dim, (1, 2), 2, 'target A Channel', target[1,0:,0:].cpu())\n",
    "\n",
    "        # target B\n",
    "        pltSubpot(graph_dim, (1, 4), 2, 'target B Channel', target[2,0:,0:].cpu())\n",
    "\n",
    "        # output L\n",
    "        pltSubpot(graph_dim, (2, 0), 2, 'Output L Channel', out[0,0:,0:].cpu().detach())\n",
    "\n",
    "        # output A\n",
    "        pltSubpot(graph_dim, (2, 2), 2, 'Output A Channel', out[1,0:,0:].cpu().detach())\n",
    "\n",
    "        # output B\n",
    "        pltSubpot(graph_dim, (2, 4), 2, 'Output B Channel', out[2,0:,0:].cpu().detach())        \n",
    "        \n",
    "    else:\n",
    "        # target L\n",
    "        pltSubpot(graph_dim, (1, 0), 1, 'target L Channel', target[0,0:,0:].cpu())\n",
    "\n",
    "        # target A\n",
    "        pltSubpot(graph_dim, (1, 1), 1, 'target A Channel', target[1,0:,0:].cpu())\n",
    "\n",
    "        # target B\n",
    "        pltSubpot(graph_dim, (1, 2), 1, 'target B Channel', target[2,0:,0:].cpu())\n",
    "\n",
    "        # output L\n",
    "        pltSubpot(graph_dim, (1, 3), 1, 'Output L Channel', out[0,0:,0:].cpu().detach())\n",
    "\n",
    "        # output A\n",
    "        pltSubpot(graph_dim, (1, 4), 1, 'Output A Channel', out[1,0:,0:].cpu().detach())\n",
    "\n",
    "        # output B\n",
    "        pltSubpot(graph_dim, (1, 5), 1, 'Output B Channel', out[2,0:,0:].cpu().detach())\n",
    "        \n",
    "        # Validation Loss Graph\n",
    "        plt.subplot2grid(graph_dim, (2, 0), colspan=3)\n",
    "        plt.plot(val_accuracies, label = 'Validation Accuracy')\n",
    "        plt.xlabel('Epoch', fontdict = {'fontsize': 15})\n",
    "        plt.title('Accuracy', fontdict = {'fontsize': 20})\n",
    "        plt.legend(fontsize='x-large')\n",
    "\n",
    "        # Validation Loss Graph\n",
    "        plt.subplot2grid(graph_dim, (2, 3), colspan=3)\n",
    "        plt.plot(val_losses, label = 'Validation Loss')\n",
    "        plt.xlabel('Epoch', fontdict = {'fontsize': 15})\n",
    "        plt.title('Loss', fontdict = {'fontsize': 20})\n",
    "        plt.legend(fontsize='x-large')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if savePath != None:\n",
    "        if name == None:\n",
    "            plt.savefig(f'{savePath}/result.jpg')\n",
    "        else:\n",
    "            plt.savefig(f'{savePath}/{name}.jpg')\n",
    "    \n",
    "    if not show:\n",
    "        plt.close(fig)\n",
    "        print('Plot Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelSampleOut(t_model, idx = [1,2,3,4,5], savePath = None, saveTarget = False, result = None, show = False, realLife = None):\n",
    "    if realLife == None:\n",
    "        inp_list = tuple([dataset[list(test_sampler.indices)[j]][0] for j in idx])\n",
    "        inp_list = torch.stack(inp_list)\n",
    "    else:\n",
    "        inp_list = realLife.cuda()\n",
    "    \n",
    "    if saveTarget:\n",
    "        inp = tuple([dataset[list(test_sampler.indices)[j]][0] for j in idx])\n",
    "        inp = torch.stack(inp)\n",
    "        \n",
    "        tgt = tuple([dataset[list(test_sampler.indices)[j]][1] for j in idx])\n",
    "        tgt = torch.stack(tgt)\n",
    "        \n",
    "        out = torch.cat((inp, tgt), 1)\n",
    "    else:\n",
    "        out = t_model(inp_list.cpu())\n",
    "    \n",
    "    fig = plt.figure(figsize=(35,5), dpi=45)\n",
    "    \n",
    "    graph_dim = (1, 7)\n",
    "    \n",
    "    if not Path(f'{savePath}').is_dir():\n",
    "        Path.mkdir(Path(f'{savePath}'))\n",
    "    \n",
    "    if not saveTarget:\n",
    "        # Model Info Label\n",
    "        plt.subplot2grid(graph_dim, (0, 0), colspan=1)\n",
    "        if result != None:\n",
    "            plt.text(.3, .5, \n",
    "                     modelInfo(2, ['Test Loss', 'Test Accuracy']), \n",
    "                     dict(size=25),  \n",
    "                     verticalalignment='center')\n",
    "        else:\n",
    "            plt.text(.3, .5, \n",
    "                     modelInfo(2), \n",
    "                     dict(size=25),  \n",
    "                     verticalalignment='center')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Model Info Label\n",
    "        plt.subplot2grid(graph_dim, (0, 1), colspan=1)\n",
    "        if result != None:\n",
    "            plt.text(.3, .5, \n",
    "                     modelInfo(3, result), \n",
    "                     dict(size=25),  \n",
    "                     verticalalignment='center')\n",
    "        else:\n",
    "            plt.text(.3, .5, \n",
    "                     modelInfo(3), \n",
    "                     dict(size=25),  \n",
    "                     verticalalignment='center')\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        plt.subplot2grid(graph_dim, (0, 0), colspan=2)\n",
    "        plt.text(0.5, 0.5, \n",
    "                 \"Target Images\", \n",
    "                 dict(size=25),\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # sample 1\n",
    "    pltSubpot(graph_dim, (0, 2), 1, 'Sample 1', getRGB(out[0]).permute(1,2,0), titleShow=False)\n",
    "    \n",
    "    # sample 2\n",
    "    pltSubpot(graph_dim, (0, 3), 1, 'Sample 2', getRGB(out[1]).permute(1,2,0), titleShow=False)\n",
    "    \n",
    "    # sample 3\n",
    "    pltSubpot(graph_dim, (0, 4), 1, 'Sample 3', getRGB(out[2]).permute(1,2,0), titleShow=False)\n",
    "    \n",
    "    # sample 4\n",
    "    pltSubpot(graph_dim, (0, 5), 1, 'Sample 4', getRGB(out[3]).permute(1,2,0), titleShow=False)\n",
    "    \n",
    "    # sample 5\n",
    "    pltSubpot(graph_dim, (0, 6), 1, 'Sample 5', getRGB(out[4]).permute(1,2,0), titleShow=False)\n",
    "    \n",
    "    plt.tight_layout(pad=1.0, h_pad=1.0)\n",
    "    \n",
    "    if realLife != None:\n",
    "        outputFile = 'RealOut'\n",
    "    else:\n",
    "        outputFile = 'SampleOutputs'\n",
    "        \n",
    "    if saveTarget:\n",
    "        plt.savefig(f'{savePath}/Targets.jpg')\n",
    "    else:\n",
    "        plt.savefig(f'{savePath}/{outputFile}.jpg')\n",
    "    \n",
    "    if not show:\n",
    "        plt.close(fig)\n",
    "        print('Plot Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samplesOut(t_model, idx = [1,2,3,4,5], savePath = None, saveTarget = False, show = False, grayScale = False, realLife = None):\n",
    "    if realLife == None:\n",
    "        inp_list = tuple([dataset[list(test_sampler.indices)[j]][0] for j in idx])\n",
    "        inp_list = torch.stack(inp_list)\n",
    "    else:\n",
    "        inp_list = realLife\n",
    "    \n",
    "    if saveTarget:\n",
    "        inp = tuple([dataset[list(test_sampler.indices)[j]][0] for j in idx])\n",
    "        inp = torch.stack(inp)\n",
    "        \n",
    "        tgt = tuple([dataset[list(test_sampler.indices)[j]][1] for j in idx])\n",
    "        tgt = torch.stack(tgt)\n",
    "        \n",
    "        out = torch.cat((inp, tgt), 1)\n",
    "    else:\n",
    "        out = t_model(inp_list.cpu())\n",
    "    \n",
    "    if not Path(f'{savePath}').is_dir():\n",
    "        Path.mkdir(Path(f'{savePath}'))\n",
    "    \n",
    "    if not Path(f'./TargetSample').is_dir():\n",
    "        Path.mkdir(Path(f'./TargetSample'))\n",
    "    \n",
    "    if not Path(f'./InputSample').is_dir():\n",
    "        Path.mkdir(Path(f'./InputSample'))\n",
    "    \n",
    "    if grayScale:\n",
    "        for i, inpt in enumerate(inp_list):\n",
    "            fig = plt.figure(figsize=(10, 10), dpi=45)\n",
    "\n",
    "            graph_dim = (1, 1)\n",
    "\n",
    "            # sample 1\n",
    "            pltSubpot(graph_dim, (0, 0), 1, '', inpt.permute(1,2,0), titleShow=False)\n",
    "\n",
    "            plt.tight_layout(pad=1.0, h_pad=1.0)  \n",
    "            \n",
    "            if realLife == None:\n",
    "                plt.savefig(f'./InputSample/G{i+1}.jpg')\n",
    "            else:\n",
    "                plt.savefig(f'./RealTest/{i+1}.jpg')\n",
    "                \n",
    "            if not show:\n",
    "                plt.close(fig)\n",
    "                print('Plot Saved')\n",
    "    else:\n",
    "        for i, o in enumerate(out):\n",
    "            fig = plt.figure(figsize=(10, 10), dpi=45)\n",
    "\n",
    "            graph_dim = (1, 1)\n",
    "\n",
    "            # sample 1\n",
    "            pltSubpot(graph_dim, (0, 0), 1, '', getRGB(o).permute(1,2,0), titleShow=False)\n",
    "\n",
    "            plt.tight_layout(pad=1.0, h_pad=1.0)  \n",
    "            \n",
    "            if realLife != None:\n",
    "                fn = 'R'\n",
    "            else:\n",
    "                fn = 'S'\n",
    "                \n",
    "            if saveTarget:\n",
    "                plt.savefig(f'./TargetSample/T{i+1}.jpg')\n",
    "            else:\n",
    "                plt.savefig(f'{savePath}/{fn}{i+1}.jpg')\n",
    "\n",
    "            if not show:\n",
    "                plt.close(fig)\n",
    "                print('Plot Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading previous losses and accuracies\n",
    "def loadModelData(directory='./Saved/'):\n",
    "    acc = []\n",
    "    los = []\n",
    "    if not Path('./Saved').is_dir():\n",
    "        Path.mkdir(Path('./Saved'))\n",
    "        \n",
    "    if Path(directory).is_dir():\n",
    "        if os.path.exists(f'{directory}/modelParams.pth'):\n",
    "            model.load_state_dict(torch.load(f'{directory}/modelParams.pth'))\n",
    "    else:\n",
    "        Path.mkdir(Path(directory))\n",
    "        \n",
    "    try:\n",
    "        with open(f'{directory}/accuracies.txt', 'r') as fd:\n",
    "            acc = [float(acc.rstrip()) for acc in fd.readlines()]\n",
    "\n",
    "        with open(f'{directory}/losses.txt', 'r') as fd:\n",
    "            los = [float(losses.rstrip()) for losses in fd.readlines()]\n",
    "    except IOError:\n",
    "        print('file not Found')\n",
    "    \n",
    "    return acc, los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model parameters to the disk\n",
    "def saveModelData(directory='./Saved/', testScore = None):\n",
    "    torch.save(model.state_dict(), f'{directory}/modelParams.pth')\n",
    "    \n",
    "    if testScore != None:\n",
    "        with open(f'{directory}/testScore.txt', 'w') as fd:\n",
    "                fd.writelines(f\"{i}\\n\" for i in testScore)\n",
    "            \n",
    "    with open(f'{directory}/accuracies.txt', 'w') as fd:\n",
    "            fd.writelines(f\"{acc:.10f}\\n\" for acc in val_accuracies)\n",
    "\n",
    "    with open(f'{directory}/losses.txt', 'w') as fd:\n",
    "        fd.writelines(f\"{losses:.10f}\\n\" for losses in val_losses) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spcifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"Unet++\"                # Unet, Unet++\n",
    "encoder = \"resnet152\"          # resnet18, resnet34, resnet50, resnet101, resnet152, inceptionresnetv2, efficientnet_b6, dpn98\n",
    "colorsspace = \"LAB\"            # Lab, RGB\n",
    "loss_fn = \"MSELoss+MS-SSIM\"    # MS-SSIM, MSELoss, MSELoss+MS-SSIM\n",
    "embedding = \"vgg16\"            # none, resnet50, vgg16\n",
    "enc_wei = \"imagenet\"           # imagenet, swsl, ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInfo(choice = 1, result = None):\n",
    "    info = ''\n",
    "    if choice == 1:\n",
    "        info = f\"Architecture\\t: {arch}\\nEncoder\\t\\t: {encoder.capitalize()}\\nLoss in ColorSpace\\t: {colorsspace}\\nLoss Function\\t: {loss_fn}\\nEmbedding\\t: {embedding.capitalize()}\\nEncoder Weights\\t: {enc_wei.capitalize()}\"\n",
    "        return \n",
    "    elif choice == 2:\n",
    "        info = f\"Architecture\\nEncoder\\nLoss in ColorSpace\\nLoss Function\\nEmbedding\\nEncoder Weights\"\n",
    "        if result != None:\n",
    "            for i in result:\n",
    "                info = info+f'\\n{i}'\n",
    "    else:\n",
    "        info = f\": {arch}\\n: {encoder.capitalize()}\\n: {colorsspace}\\n: {loss_fn}\\n: {embedding.capitalize()}\\n: {enc_wei.capitalize()}\"\n",
    "        if result != None:\n",
    "            for i in result:\n",
    "                info = info+f'\\n: {i}'\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specFromName(name):\n",
    "    spec = name.split('_')\n",
    "    return [spec[0], spec[1].lower(), spec[2], spec[3], spec[4].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './Saved/'\n",
    "model_data_folders = os.listdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Choose a Model >>\\n')\n",
    "for i, md in enumerate(model_data_folders):\n",
    "    print(f'{(i+1):2d}. {md}')\n",
    "\n",
    "user_choice = True\n",
    "if user_choice:\n",
    "    md_in = int(input())\n",
    "else:\n",
    "    md_in = int(5)\n",
    "\n",
    "mode_data = model_data_folders[md_in-1]\n",
    "\n",
    "arch, encoder, colorsspace, loss_fn, embedding = specFromName(mode_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColorNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorNet(nn.Module):\n",
    "    def __init__(self, model, testMode = False, resultMode = False, balance=1):\n",
    "        super(ColorNet, self).__init__()\n",
    "        self.testMode = testMode\n",
    "        self.resultMode = resultMode\n",
    "        self.balance = balance\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if self.testMode or self.resultMode :\n",
    "            self.net = model.eval()\n",
    "        else:\n",
    "            self.net = model\n",
    "        \n",
    "        self.out = nn.Sequential(      \n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.net(x)\n",
    "        \n",
    "        out = self.out(out * self.balance)\n",
    "        \n",
    "        if self.resultMode:\n",
    "            out = torch.cat((x, out), 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'Unet++':\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name = encoder,\n",
    "        encoder_weights = enc_wei,\n",
    "        in_channels = 1,\n",
    "        classes = 2,\n",
    "        activation = None,\n",
    "    ).cuda()\n",
    "else:\n",
    "    model = smp.Unet(\n",
    "        encoder_name = encoder,\n",
    "        encoder_weights = \"imagenet\",\n",
    "        in_channels = 1,\n",
    "        classes = 2,\n",
    "        activation = None,\n",
    "    ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_Arc-Encoder-ColorSpace-Loss-Embedding.pth'\n",
    "model_save_file = f'{arch}_{encoder.capitalize().replace(\"_\", \"-\")}_{colorsspace}_{loss_fn}_{embedding.capitalize()}'\n",
    "model_dir_name = f'./Saved/{model_save_file}'\n",
    "\n",
    "val_accuracies, val_losses = loadModelData(directory=model_dir_name)\n",
    "    \n",
    "# loss_fn = MS_SSIM(data_range=255, size_average=False, channel=2)\n",
    "# criterion = [nn.MSELoss(), MS_SSIM(data_range=255, size_average=True, channel=2)]\n",
    "criterion = nn.MSELoss()\n",
    "metric = MS_SSIM(data_range=255, size_average=True, channel=2)\n",
    "\n",
    "learning_rate = 1e-04\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, eps=1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embededNet():\n",
    "    if 'resnet' in embedding:\n",
    "        # resnet\n",
    "        embededNet = models.resnet50(pretrained = True, progress=True).cuda()\n",
    "        for param in embededNet.parameters():\n",
    "            param.requires_grad = False\n",
    "        embededNet = nn.Sequential(*list(embededNet.children())[:-2]).cuda()\n",
    "    else:\n",
    "        # vgg\n",
    "        embededNet = models.vgg16(pretrained = True, progress=True).cuda()\n",
    "        for param in embededNet.parameters():\n",
    "            param.requires_grad = False\n",
    "        embededNet = nn.Sequential(*list(embededNet.children())[:-2]).cuda()\n",
    "        \n",
    "    return embededNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Calculation\n",
    "def getLoss(MseLoss, preds, targs, epred=None, etarg=None):\n",
    "    ms = MS_SSIM(data_range=255, size_average=True, channel=preds.shape[1])\n",
    "    #Loss Calculation\n",
    "    if loss_fn == 'MS-SSIM':\n",
    "        # Ex. X_X_X_MS-SSIM_X\n",
    "        loss = 1 - ms(preds, targs)\n",
    "        # print(6)\n",
    "    elif loss_fn == 'MSELoss':\n",
    "        if epred == None:\n",
    "            # Ex. X_X_X_MSELoss_none\n",
    "            loss = MseLoss(preds, targs) / 255\n",
    "            # print(7)\n",
    "        else:\n",
    "            # Ex. X_X_X_MSELoss_X\n",
    "            loss = MseLoss(torch.tanh(epred), torch.tanh(etarg))\n",
    "            # print(8)\n",
    "    else:\n",
    "        loss1 = 1 - ms(preds, targs)\n",
    "        \n",
    "        if epred == None:\n",
    "            # Ex. X_X_X_MSELoss+MS-SSIM_none\n",
    "            loss2 = MseLoss(preds, targs) / 255\n",
    "            # print(9)\n",
    "        else:\n",
    "            # Ex. X_X_X_MSELoss+MS-SSIM_X\n",
    "            loss2 = MseLoss(torch.tanh(epred), torch.tanh(etarg))\n",
    "            # print(10)\n",
    "            \n",
    "        loss = (loss1 + loss2) * 0.5\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss of a batch    \n",
    "def loss_batch(model, loss_func, inputs, targets, optimizer=None, metric=None):\n",
    "    # calculate the loss\n",
    "    predictions = model(inputs.cuda())\n",
    "    \n",
    "    predictions = predictions.cuda()\n",
    "    targets = targets.cuda()\n",
    "    inputs = inputs.cuda()\n",
    "    \n",
    "    # Accuracy Calculation\n",
    "    accuracy = None\n",
    "    if metric is not None:\n",
    "        # compute the metric\n",
    "        m_preds = getRGBs(torch.cat((inputs, predictions), 1))\n",
    "        m_targs = getRGBs(torch.cat((inputs, targets), 1))\n",
    "        \n",
    "        ms = MS_SSIM(data_range=255, size_average=True, channel=m_targs.shape[1])\n",
    "        accuracy = ms(m_preds, m_targs)\n",
    "    \n",
    "    \n",
    "    # Loss Calculation\n",
    "    loss = 0\n",
    "    if embedding == 'none':\n",
    "        if colorsspace.lower() == 'lab':\n",
    "            # Ex. X_X_Lab_X_none\n",
    "            preds = ((predictions * 128) + 128).float()           # 2 x 256 x 256\n",
    "            targs = ((targets * 128) + 128).float()               # 2 x 256 x 256\n",
    "            \n",
    "            loss = getLoss(loss_func, preds, targs)               # 2 x 256 x 256\n",
    "            # print(1)\n",
    "        else:\n",
    "            # Ex. X_X_RGB_X_none\n",
    "            preds = getRGBs(torch.cat((inputs, predictions), 1))  # 3 x 256 x 256\n",
    "            targs = getRGBs(torch.cat((inputs, targets), 1))      # 3 x 256 x 256\n",
    "            \n",
    "            loss = getLoss(loss_func, preds, targs)               # 3 x 256 x 256\n",
    "            # print(2)\n",
    "            \n",
    "    else:\n",
    "        embNet = embededNet() # resnet50, vgg16\n",
    "        if colorsspace.lower() == 'lab':\n",
    "            preds = ((predictions * 128) + 128).float()           # 2 x 256 x 256\n",
    "            targs = ((targets * 128) + 128).float()               # 2 x 256 x 256\n",
    "            inps = ((inputs * 100) + 50).float()                  # 1 x 256 x 256\n",
    "            \n",
    "            e_preds = embNet(torch.cat((inps, preds), 1))         # 3 x 256 x 256\n",
    "            e_targs = embNet(torch.cat((inps, targs), 1))         # 3 x 256 x 256\n",
    "            \n",
    "            loss = getLoss(loss_func, preds, targs, e_preds, e_targs)\n",
    "            # print(4)\n",
    "        else:\n",
    "            preds = getRGBs(torch.cat((inputs, predictions), 1))  # 3 x 256 x 256\n",
    "            targs = getRGBs(torch.cat((inputs, targets), 1))      # 3 x 256 x 256\n",
    "            \n",
    "            e_preds = embNet(preds)                               # 3 x 256 x 256\n",
    "            e_targs = embNet(targs)                               # 3 x 256 x 256\n",
    "            \n",
    "            loss = getLoss(loss_func, preds, targs, e_preds, e_targs)\n",
    "            # print(6)\n",
    "    \n",
    "    \n",
    "    # Back Propagation\n",
    "    if optimizer is not None:\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return loss, len(inputs), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "def evaluate(model, criterion, valid_dl, metric=None):\n",
    "    with torch.no_grad():\n",
    "        # pass each batch throgh the model\n",
    "        results = [loss_batch(model, criterion, input_batch, target_batch, metric = metric)\n",
    "                 for input_batch, target_batch in valid_dl]\n",
    "        \n",
    "        # seperate losses, counts and matrices\n",
    "        losses, nums, metrices = zip(*results)\n",
    "        \n",
    "        # total size of the dataset\n",
    "        total = np.sum(nums)\n",
    "        \n",
    "        # Avg. loss across batches\n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "        avg_metric = None\n",
    "        \n",
    "        if metric is not None:\n",
    "            # Avg. metric accross batches\n",
    "            avg_metric = np.sum(np.multiply(metrices, nums)) / total\n",
    "            \n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, criterion, optimizer, train_dl, val_dl, metric=None):\n",
    "    for epoch in trange(epochs):\n",
    "        # training\n",
    "        for input_batch, target_batch in tqdm(train_dl):\n",
    "            train_loss, train_total, train_metric = loss_batch(model, criterion, input_batch, target_batch, optimizer, metric)\n",
    "            \n",
    "        #evaluation\n",
    "        result = evaluate(model, criterion, val_dl, metric)\n",
    "        val_loss, val_total, val_metric = result\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "        \n",
    "        val_accuracies.append(val_metric)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # print progress\n",
    "        if metric is None:\n",
    "            print(f\"Epoch : [{epoch+1}/{epochs}], Loss : {val_loss:.5f}\")\n",
    "        else:            \n",
    "            print(f\"Epoch : [{epoch+1}/{epochs}], Loss : {val_loss:.5f}, Accuracy : {val_metric:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testResult(ColorNet(model.eval().cpu(), True, True), 75, f'{model_dir_name}/Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitLoop(epoch = 10, lr = 1e-4, skip = True):\n",
    "    if not skip:\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        fit(epoch, ColorNet(model.cuda()), criterion, optimizer, train_dl, val_dl, metric)\n",
    "        saveModelData(directory=model_dir_name)\n",
    "        testResult(ColorNet(model.eval().cpu(), True, True), 75, model_dir_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitLoop(5, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitLoop(5, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitLoop(5, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitLoop(5, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result on TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ACCURACY\n",
    "test_loss, total, test_acc = evaluate(ColorNet(model.eval().cuda(), True), criterion, test_dl, metric)\n",
    "print(f\"Loss : {test_loss:.4f}, Accuracy : {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModelData(directory=model_dir_name, testScore = [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testResult(ColorNet(model.eval().cpu(), True, True), 75, model_dir_name, show=False)\n",
    "# testResult(ColorNet(model.eval().cpu(), True, True), 1, model_dir_name, 'S1', show=False)\n",
    "# testResult(ColorNet(model.eval().cpu(), True, True), 10, model_dir_name, 'S2', show=False)\n",
    "# testResult(ColorNet(model.eval().cpu(), True, True), 25, model_dir_name, 'S3', show=False)\n",
    "# testResult(ColorNet(model.eval().cpu(), True, True), 28, model_dir_name, 'S4', show=False)\n",
    "# testResult(ColorNet(model.eval().cpu(), True, True), 42, model_dir_name, 'S5', show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = [1, 10, 25, 28, 42]\n",
    "modelSampleOut(ColorNet(model.eval().cpu(), True, True), img_idx, f'{model_dir_name}/Results', saveTarget = False, result = [f'{test_loss:.6f}', f'{test_acc:.6f}'], show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesOut(ColorNet(model.eval().cpu(), True, True), img_idx, f'{model_dir_name}/Results', saveTarget = False, show = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samplesOut(ColorNet(model.eval().cpu(), True, True), img_idx, f'{model_dir_name}/Results', saveTarget = True, show = False, grayScale = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RealLife Grayscale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDir = './RealTest/'\n",
    "testImg = os.listdir(testDir)\n",
    "img_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImgs = []\n",
    "for ti in testImg:\n",
    "    timg = cv2.imread(f'{testDir}{ti}')\n",
    "    timg = cv2.resize(timg, (img_dim, img_dim))\n",
    "    timg = torch.from_numpy(timg).permute(2,0,1) / 255 - .5\n",
    "    testImgs.append(timg[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImgs = torch.stack(tuple(testImgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(1, 5, figsize=(50, 10), dpi=45)\n",
    "graph_dim = (1, 5)\n",
    "\n",
    "for i, ti in enumerate(testImgs):\n",
    "    pltSubpot(graph_dim, (0, i), 1, '', ti.permute(1,2,0), titleShow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSampleOut(ColorNet(model.eval().cpu(), True, True), img_idx, f'{model_dir_name}/Results', saveTarget = False, result = [f'{test_loss:.6f}', f'{test_acc:.6f}'], show = True, realLife = testImgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesOut(ColorNet(model.eval().cpu(), True, True), img_idx, f'{model_dir_name}/Results', saveTarget = False, show = False, realLife = testImgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
